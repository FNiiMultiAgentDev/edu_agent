{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EduAgent20250629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 跑通批改流程，验证了大题针对性批改策略的可行性\n",
    "## 政治、物理、数学、地理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路：先用API请求最强大的模型验证可行性；再迁移到备选的开源模型；最终落实到本地部署模型接管全流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物理 数学：把答案拆分为基本的给分单元，对每个给分单元进行详细评分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图片描述](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Literal\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "question_path = \"question.txt\"\n",
    "ground_truth_answer_path = \"ground_truth_answer.txt\"\n",
    "explanation_of_ground_truth_answer_path = \"explanation.txt\"\n",
    "few_shot_path = \"few_shot_example.json\"\n",
    "student_answer_path = \"student_answer.txt\"\n",
    "\n",
    "question = pd.read_table(f\"{question_path}\")\n",
    "ground_truth_answer = pd.read_table(f\"{ground_truth_answer_path}\")\n",
    "explanation_of_ground_truth_answer = pd.read_table(f\"{explanation_of_ground_truth_answer_path}\")\n",
    "few_shot = pd.read_table(f\"{few_shot_path}\")\n",
    "student_answer = pd.read_table(f\"{student_answer_path}\")\n",
    "\n",
    "class PointsEarnedAndWhy(BaseModel):\n",
    "    points_earned_of_this_equation:int\n",
    "    why: str\n",
    "\n",
    "class CorrectionAndExplanation(BaseModel):\n",
    "    formula1 : PointsEarnedAndWhy\n",
    "    formula2 : PointsEarnedAndWhy\n",
    "    formula3 : PointsEarnedAndWhy\n",
    "\n",
    "# 定义结构化输出的数据模型\n",
    "class QuestionGrading(BaseModel):\n",
    "    points_earned_of_this_question: float\n",
    "    correction_and_explanation: CorrectionAndExplanation\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"o4-mini\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"现在你是一个中学老师，你要负责批改你学生的物理试卷的题目，主任要求你严格按照题目解析与各点评分标准里的踩分点来进行批改得分，并对每一个踩分点进行解释，比如说这个踩分点有对应的公式，得到相应的分数，那个踩分点没有公式或者公式错误，不得分\"}, # 角色扮演 背景介绍\n",
    "            {\"type\": \"input_text\", \"text\": f\"题目：{question}\"},\n",
    "            {\"type\": \"input_text\", \"text\": f\"标准答案：{ground_truth_answer}\"},\n",
    "            {\"type\": \"input_text\", \"text\": f\"题目解析与各点评分标准：{explanation_of_ground_truth_answer}\"},\n",
    "            {\"type\": \"input_text\", \"text\": f\"批改示例：{few_shot}\"},\n",
    "            {\"type\": \"input_text\", \"text\": f\"学生答案：{student_answer}\"},\n",
    "        ],\n",
    "    }],\n",
    "    text_format = QuestionGrading,\n",
    ")\n",
    "\n",
    "# print(\"现在你是一个中学老师，你要负责批改你学生的物理试卷的题目，主任要求你严格按照题目解析与各点评分标准里的踩分点来进行批改得分，并对每一个踩分点进行解释，比如说这个踩分点有对应的公式，得到相应的分数，那个踩分点没有公式或者公式错误，不得分\")\n",
    "# print(f\"题目：{question}\")\n",
    "# print(f\"标准答案：{ground_truth_answer}\")\n",
    "# print(f\"题目解析与各点评分标准：{explanation_of_ground_truth_answer}\")\n",
    "# print(f\"批改示例：{few_shot}\")\n",
    "# print(f\"学生答案：{student_answer}\")\n",
    "print(\"第一轮对话\",response.output_parsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 政治 历史 地理：高亮标识可能的得分点，大大减轻阅卷老师的视觉负担，把复杂的综合研判过程简化为“接受或拒绝“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 政治：教材原文优先，用确定性技术方案来匹配 --> difflib 最大公共字符串\n",
    "### 历史 地理：语义空间更加灵活，可采用自然语义匹配 --> 本地部署embedding模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCDEFG经济全球化: 0.5882352941176471\n",
      "经济全球: 0.8888888888888888\n",
      "经济全球化: 1.0\n",
      "经济的全球化: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def get_similarity(target_str, compare_str):\n",
    "    return SequenceMatcher(None, target_str, compare_str).ratio()\n",
    "\n",
    "target_str = \"经济全球化\"\n",
    "compare_set = [\"ABCDEFG经济全球化\", \"经济全球\", \"经济全球化\", \"经济的全球化\"]\n",
    "\n",
    "for compare_str in compare_set:\n",
    "    similarity = get_similarity(target_str, compare_str)\n",
    "    print(f\"{compare_str}: {similarity}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "import ollama\n",
    "import chromadb\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def get_center_y(box):\n",
    "    return (box[0][1] + box[3][1]) / 2\n",
    "\n",
    "def group_by_lines(char_list, y_thresh=15):\n",
    "    \"\"\"将字符按Y坐标聚类为多行\"\"\"\n",
    "    lines = []\n",
    "    for ch in char_list:\n",
    "        cy = get_center_y(ch['box'])\n",
    "        matched = False\n",
    "        for line in lines:\n",
    "            line_cy = get_center_y(line[0]['box'])\n",
    "            if abs(cy - line_cy) < y_thresh:\n",
    "                line.append(ch)\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            lines.append([ch])\n",
    "    return lines\n",
    "\n",
    "def build_colored_path_from_lines(line_groups):\n",
    "    \"\"\"将多行字符构造成一个连续染色区域（首尾字符拼接）\"\"\"\n",
    "    path_points = []\n",
    "    for line in line_groups:\n",
    "        first = line[0]['box']\n",
    "        last = line[-1]['box']\n",
    "        tl = first[0]\n",
    "        bl = first[3]\n",
    "        tr = last[1]\n",
    "        br = last[2]\n",
    "        path_points.extend([tl, tr, br, bl])\n",
    "    return [list(map(int, pt)) for pt in path_points]\n",
    "\n",
    "# 初始化 OCR\n",
    "ocr = PaddleOCR(use_textline_orientation=True, lang='ch')\n",
    "res = ocr.predict(\"image_input.png\")[0]\n",
    "\n",
    "texts = res['rec_texts']\n",
    "scores = res['rec_scores']\n",
    "boxes = res['rec_polys']\n",
    "\n",
    "# 构建字符级序列\n",
    "char_stream = []\n",
    "for text, score, box in zip(texts, scores, boxes):\n",
    "    chars = list(text.strip())\n",
    "    n = len(chars)\n",
    "    box = np.array(box)\n",
    "    top_line = np.linspace(box[0], box[1], n + 1)\n",
    "    bottom_line = np.linspace(box[3], box[2], n + 1)\n",
    "    for i, ch in enumerate(chars):\n",
    "        tl = top_line[i]\n",
    "        tr = top_line[i+1]\n",
    "        br = bottom_line[i+1]\n",
    "        bl = bottom_line[i]\n",
    "        char_box = np.array([tl, tr, br, bl], dtype=int).tolist()\n",
    "        char_stream.append({'char': ch, 'box': char_box, 'score': score})\n",
    "\n",
    "print(char_stream[0])\n",
    "\n",
    "# 构建全文\n",
    "full_text = ''.join([c['char'] for c in char_stream])\n",
    "\n",
    "# 切分为句子（排除顿号）\n",
    "split_pattern = re.compile(r\"([，。！？；：])\")\n",
    "segments = []\n",
    "start_idx = 0\n",
    "for match in split_pattern.finditer(full_text):\n",
    "    end_idx = match.end()\n",
    "    segment_text = full_text[start_idx:end_idx]\n",
    "    segment_chars = char_stream[start_idx:end_idx]\n",
    "    line_groups = group_by_lines(segment_chars)\n",
    "    polygon_path = build_colored_path_from_lines(line_groups)\n",
    "    segments.append({\n",
    "        'text': segment_text,\n",
    "        'box': polygon_path,\n",
    "        'score': np.mean([c['score'] for c in segment_chars])\n",
    "    })\n",
    "    start_idx = end_idx\n",
    "\n",
    "# 处理结尾残余\n",
    "if start_idx < len(full_text):\n",
    "    segment_chars = char_stream[start_idx:]\n",
    "    segment_text = full_text[start_idx:]\n",
    "    line_groups = group_by_lines(segment_chars)\n",
    "    polygon_path = build_colored_path_from_lines(line_groups)\n",
    "    segments.append({\n",
    "        'text': segment_text,\n",
    "        'box': polygon_path,\n",
    "        'score': np.mean([c['score'] for c in segment_chars])\n",
    "    })\n",
    "'''\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"test_2\")\n",
    "\n",
    "# store each document in a vector embedding database\n",
    "for i, item in enumerate(segments):\n",
    "  response = ollama.embed(model=\"mxbai-embed-large\", input=item['text'])\n",
    "  embeddings = response[\"embeddings\"]\n",
    "  collection.add(\n",
    "    ids=[str(i)],\n",
    "    embeddings=embeddings,\n",
    "    documents=[item['text']],\n",
    "  )\n",
    "\n",
    "target = \"推动经济全球化朝着更加开放、包容、普惠、平衡的方向发展\"\n",
    "target_embedding = ollama.embed(\n",
    "  model=\"mxbai-embed-large\",\n",
    "  input=target\n",
    ")\n",
    "query_result = collection.query(\n",
    "  query_embeddings=[target_embedding[\"embeddings\"][0]],\n",
    "  n_results=1\n",
    ")\n",
    "best_match = segments[int(query_result['ids'][0][0])]\n",
    "'''\n",
    "\n",
    "#difflib 匹配关键词\n",
    "target = \"推动经济全球化朝着更加开放、包容、普惠、平衡的方向发展\"\n",
    "best_match = None\n",
    "best_score = 0\n",
    "\n",
    "for item in segments:\n",
    "    sim = SequenceMatcher(None, item['text'], target).ratio()\n",
    "    item['sim'] = sim\n",
    "    if sim > best_score:\n",
    "        best_score = sim\n",
    "        best_match = item\n",
    "\n",
    "# 输出结果\n",
    "print(\"🎯 匹配结果（按重组后句子）:\")\n",
    "for item in segments:\n",
    "    print(f\"文字：{item['text']}，相似度：{item['sim']:.2f}，坐标点数：{len(item['box'])}，坐标：{item['box']}\")\n",
    "\n",
    "print(\"\\n🔥 最佳匹配:\")\n",
    "print(f\"文本：{best_match['text']}，相似度：{best_match['sim']:.2f}，坐标：{best_match['box']}\")\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# 加载原图（确保是RGBA）\n",
    "base = Image.open(\"image_input.png\").convert(\"RGBA\")\n",
    "\n",
    "# 创建一个透明图层\n",
    "overlay = Image.new(\"RGBA\", base.size, (0, 0, 0, 0))\n",
    "draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "# 绘制半透明红色多边形到 overlay上\n",
    "i = 0\n",
    "\n",
    "while i < len(best_match['box']):\n",
    "    draw.polygon(best_match['box'][i:i+4], fill=(255, 0, 0, 100))  # alpha=100 表示半透明\n",
    "    i += 4\n",
    "\n",
    "# 合成原图与染色图层\n",
    "out = Image.alpha_composite(base, overlay)\n",
    "\n",
    "# 保存最终效果\n",
    "out.save(\"output_baidu.png\")\n",
    "print(\"✅ 染色结果已更新为半透明红色并保存为 output_baidu.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试qwen系列能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'points_earned_of_this_question': 4, 'correction_and_explanation': {'r_{乙} = \\\\frac{L}{\\\\sin 30^\\\\circ} = 2L': {'该点得分': 2, '原因': '存在该公式或其相同数学逻辑的形式，得2分'}, 'q v_0 B = m \\\\frac{v_0^2}{r_乙}': {'该点得分': 2, '原因': '存在该公式或其相同数学逻辑的形式，得2分'}, 'B = \\\\frac{m v_0}{2 q L}': {'该点得分': 0, '原因': '最终结果计算错误，正确表达式应为 $ B = \\\\frac{m v_0}{2 q L} $，而学生答案缺少了分母中的 $ L $，因此不得分'}}}\n"
     ]
    }
   ],
   "source": [
    "# 步骤 1：发出请求\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "question_path = \"question.txt\"\n",
    "ground_truth_answer_path = \"ground_truth_answer.txt\"\n",
    "explanation_of_ground_truth_answer_path = \"explanation.txt\"\n",
    "few_shot_path = \"few_shot.json\"\n",
    "student_answer_path = \"student_answer.txt\"\n",
    "\n",
    "with open(f'{question_path}', 'r', encoding='utf-8') as question_file,\\\n",
    "    open(f'{ground_truth_answer_path}', 'r', encoding='utf-8') as ground_truth_answer_file,\\\n",
    "    open(f'{explanation_of_ground_truth_answer_path}', 'r', encoding='utf-8') as explanation_of_ground_truth_answer_file,\\\n",
    "    open(f'{few_shot_path}', 'r', encoding='utf-8') as few_shot_file,\\\n",
    "    open(f'{student_answer_path}', 'r', encoding='utf-8') as student_answer_file:\n",
    "    question = question_file.read()  \n",
    "    ground_truth_answer = ground_truth_answer_file.read()\n",
    "    explanation_of_ground_truth_answer = explanation_of_ground_truth_answer_file.read()\n",
    "    few_shot = json.load(few_shot_file)\n",
    "    student_answer = student_answer_file.read()\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen3-32b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"现在你是一个中学老师，你要负责批改你学生的物理试卷的题目，\n",
    "            主任要求你严格按照题目解析与各点评分标准里的踩分点来进行批改得分，\n",
    "            并对每一个踩分点进行解释，比如说这个踩分点有对应的公式，得到相应的分数，\n",
    "            那个踩分点没有公式或者公式错误，不得分\"。按照批改示例里的“few_shot_output”的json格式输出\n",
    "            题目：{question}\n",
    "            标准答案：{ground_truth_answer}\n",
    "            题目解析与各点评分标准：{explanation_of_ground_truth_answer}\n",
    "            批改示例：{few_shot}\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"学生答案：{student_answer}\", \n",
    "        },\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    extra_body={\"enable_thinking\": False}\n",
    ")\n",
    "\n",
    "json_string = completion.choices[0].message.content\n",
    "json_string = json.loads(json_string)\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本地部署模型接管全流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤 1：发出请求\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "question_path = \"question.txt\"\n",
    "ground_truth_answer_path = \"ground_truth_answer.txt\"\n",
    "explanation_of_ground_truth_answer_path = \"explanation.txt\"\n",
    "few_shot_path = \"few_shot.json\"\n",
    "student_answer_path = \"student_answer.txt\"\n",
    "\n",
    "with open(f'{question_path}', 'r', encoding='utf-8') as question_file,\\\n",
    "    open(f'{ground_truth_answer_path}', 'r', encoding='utf-8') as ground_truth_answer_file,\\\n",
    "    open(f'{explanation_of_ground_truth_answer_path}', 'r', encoding='utf-8') as explanation_of_ground_truth_answer_file,\\\n",
    "    open(f'{few_shot_path}', 'r', encoding='utf-8') as few_shot_file,\\\n",
    "    open(f'{student_answer_path}', 'r', encoding='utf-8') as student_answer_file:\n",
    "    question = question_file.read()  \n",
    "    ground_truth_answer = ground_truth_answer_file.read()\n",
    "    explanation_of_ground_truth_answer = explanation_of_ground_truth_answer_file.read()\n",
    "    few_shot = json.load(few_shot_file)\n",
    "    student_answer = student_answer_file.read()\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    #api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"http://127.0.0.1:11434/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen3:8b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"现在你是一个中学老师，你要负责批改你学生的物理试卷的题目，\n",
    "            主任要求你严格按照题目解析与各点评分标准里的踩分点来进行批改得分，\n",
    "            并对每一个踩分点进行解释，比如说这个踩分点有对应的公式，得到相应的分数，\n",
    "            那个踩分点没有公式或者公式错误，不得分\"。按照批改示例里的“few_shot_output”的json格式输出\n",
    "            题目：{question}\n",
    "            标准答案：{ground_truth_answer}\n",
    "            题目解析与各点评分标准：{explanation_of_ground_truth_answer}\n",
    "            批改示例：{few_shot}\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"学生答案：{student_answer}\", \n",
    "        },\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    extra_body={\"enable_thinking\": False}\n",
    ")\n",
    "\n",
    "json_string = completion.choices[0].message.content\n",
    "json_string = json.loads(json_string)\n",
    "print(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
