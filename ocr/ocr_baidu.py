import re
import numpy as np
import sys
import os
import json
from paddleocr import PaddleOCR
from difflib import SequenceMatcher
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from zhengzhi.corrector import correct

def get_center_y(box):
    return (box[0][1] + box[3][1]) / 2

def group_by_lines(char_list, y_thresh=15):
    """å°†å­—ç¬¦æŒ‰Yåæ ‡èšç±»ä¸ºå¤šè¡Œ"""
    lines = []
    for ch in char_list:
        cy = get_center_y(ch['box'])
        matched = False
        for line in lines:
            line_cy = get_center_y(line[0]['box'])
            if abs(cy - line_cy) < y_thresh:
                line.append(ch)
                matched = True
                break
        if not matched:
            lines.append([ch])
    return lines

def build_colored_path_from_lines(line_groups):
    """å°†å¤šè¡Œå­—ç¬¦æ„é€ æˆä¸€ä¸ªè¿ç»­æŸ“è‰²åŒºåŸŸï¼ˆé¦–å°¾å­—ç¬¦æ‹¼æ¥ï¼‰"""
    path_points = []
    for line in line_groups:
        first = line[0]['box']
        last = line[-1]['box']
        tl = first[0]
        bl = first[3]
        tr = last[1]
        br = last[2]
        path_points.extend([tl, tr, br, bl])
    return [list(map(int, pt)) for pt in path_points]

# åˆå§‹åŒ– OCR
ocr = PaddleOCR(use_textline_orientation=True, lang='ch')
res = ocr.predict("ocr/input.jpg")[0]

texts = res['rec_texts']
scores = res['rec_scores']
boxes = res['rec_polys']

# æ„å»ºå­—ç¬¦çº§åºåˆ—
char_stream = []
for text, score, box in zip(texts, scores, boxes):
    chars = list(text.strip())
    n = len(chars)
    box = np.array(box)
    top_line = np.linspace(box[0], box[1], n + 1)
    bottom_line = np.linspace(box[3], box[2], n + 1)
    for i, ch in enumerate(chars):
        tl = top_line[i]
        tr = top_line[i+1]
        br = bottom_line[i+1]
        bl = bottom_line[i]
        char_box = np.array([tl, tr, br, bl], dtype=int).tolist()
        char_stream.append({'char': ch, 'box': char_box, 'score': score})

#print(char_stream[0])

# æ„å»ºå…¨æ–‡
full_text = ''.join([c['char'] for c in char_stream])

student_answer = full_text
with open("ocr/student_answer.txt", "w", encoding="utf-8") as f:
    f.write(student_answer)
# è°ƒç”¨ä½œä¸šæ‰¹æ”¹æ¥å£
grading_result = correct(student_answer)

# åˆ‡åˆ†ä¸ºå¥å­ï¼ˆæ’é™¤é¡¿å·ï¼‰
split_pattern = re.compile(r"([ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š. â‘  â‘¡ â‘¢ â‘£ â‘¤])")
segments = []
start_idx = 0
for match in split_pattern.finditer(full_text):
    end_idx = match.end()
    segment_text = full_text[start_idx:end_idx]
    segment_chars = char_stream[start_idx:end_idx]
    line_groups = group_by_lines(segment_chars)
    polygon_path = build_colored_path_from_lines(line_groups)
    segments.append({
        'text': segment_text,
        'box': polygon_path,
        'score': np.mean([c['score'] for c in segment_chars])
    })
    start_idx = end_idx

#å¤„ç†ç»“å°¾æ®‹ä½™
if start_idx < len(full_text):
    segment_chars = char_stream[start_idx:]
    segment_text = full_text[start_idx:]
    line_groups = group_by_lines(segment_chars)
    polygon_path = build_colored_path_from_lines(line_groups)
    segments.append({
        'text': segment_text,
        'box': polygon_path,
        'score': np.mean([c['score'] for c in segment_chars])
    })

#######################################################
###ä¸¤ä¸¤ç»„åˆã€ä¸‰ä¸‰ç»„åˆ

# å­˜æ”¾æ‰€æœ‰ç»„åˆåçš„æ–° segment
combined_segments = []

# ç›¸é‚»ä¸¤ä¸¤ç»„åˆ
for i in range(len(segments) - 1):
    seg1 = segments[i]
    seg2 = segments[i + 1]
    combined_text = seg1['text'] + seg2['text']
    combined_box = seg1['box'] + seg2['box']
    combined_score = (seg1['score'] + seg2['score']) / 2
    combined_segments.append({
        'text': combined_text,
        'box': combined_box,
        'score': combined_score
    })

# ç›¸é‚»ä¸‰æ®µç»„åˆ
for i in range(len(segments) - 2):
    seg1 = segments[i]
    seg2 = segments[i + 1]
    seg3 = segments[i + 2]
    combined_text = seg1['text'] + seg2['text'] + seg3['text']
    combined_box = seg1['box'] + seg2['box'] + seg3['box']
    combined_score = (seg1['score'] + seg2['score'] + seg3['score']) / 3
    combined_segments.append({
        'text': combined_text,
        'box': combined_box,
        'score': combined_score
    })

# æŠŠç»„åˆæ®µåŠ åˆ° segments é‡Œç»Ÿä¸€å¤„ç†
segments += combined_segments
#######################################################

with open("ocr/target_list.txt", "r", encoding="utf-8") as f:
    target_list = [line.strip() for line in f if line.strip()]

highlight_boxes = []

# éå†æ‰€æœ‰ target
for target in target_list:
    for item in segments:
        sim = SequenceMatcher(None, item['text'], target).ratio()
        item['sim'] = sim
        if sim >= 0.8:
            for point in item['box']:
                highlight_boxes.append(point)

from PIL import Image, ImageDraw

# åŠ è½½åŸå›¾ï¼ˆç¡®ä¿æ˜¯RGBAï¼‰
base = Image.open("ocr/input.jpg").convert("RGBA")

# åˆ›å»ºä¸€ä¸ªé€æ˜å›¾å±‚
overlay = Image.new("RGBA", base.size, (0, 0, 0, 0))
draw = ImageDraw.Draw(overlay)

# ç»˜åˆ¶åŠé€æ˜çº¢è‰²å¤šè¾¹å½¢åˆ° overlayä¸Š
box = highlight_boxes
for i in range(0, len(box), 4):
    draw.polygon(box[i:i+4], fill=(0, 225, 0, 100))  # æ¯4ä¸ªç‚¹ä¸ºä¸€ç»„å¤šè¾¹å½¢

# åˆæˆåŸå›¾ä¸æŸ“è‰²å›¾å±‚
out = Image.alpha_composite(base, overlay)

# ä¿å­˜æœ€ç»ˆæ•ˆæœ
out.save("ocr/output_baidu.png")
print("âœ… æŸ“è‰²ç»“æœå·²æ›´æ–°ä¸ºåŠé€æ˜çº¢è‰²å¹¶ä¿å­˜ä¸º output_baidu.png")

# å°† grading_result è½¬ä¸º dictï¼ˆå¦‚æœæ˜¯ Pydantic æ¨¡å‹ï¼‰
if hasattr(grading_result, "model_dump"):
    grading_dict = grading_result.model_dump()
elif hasattr(grading_result, "dict"):
    grading_dict = grading_result.dict()
else:
    grading_dict = grading_result  # å¦‚æœå®ƒæœ¬æ¥å°±æ˜¯å­—å…¸ç»“æ„

# æ·»åŠ æ€»å¾—åˆ†å­—æ®µï¼ˆå¦‚æœæ˜¯ä»å¤–éƒ¨æ‹¿åˆ°çš„ï¼‰
grading_dict["points_earned_of_this_question"] = getattr(grading_result, "points_earned_of_this_question", None)

# æ‰“å° JSON
print("ğŸ¯ ä½œä¸šæ‰¹æ”¹ç»“æœï¼ˆJSON æ ¼å¼ï¼‰ï¼š")
print(json.dumps(grading_dict, ensure_ascii=False, indent=2))

with open("ocr/grading_result.json", "w", encoding="utf-8") as f:
    json.dump(grading_dict, f, ensure_ascii=False, indent=2)
print("âœ… ä½œä¸šæ‰¹æ”¹ç»“æœå·²ä¿å­˜ä¸º ocr/grading_result.json")
